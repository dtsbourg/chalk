<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>dtsbourg / Thoughts | [NOTES] Self-Normalizing Neural Networks (SELU)</title>
  <meta name="description" content="by G. Klambauer, T. Unterthiner, A. Mayr, and S. Hochreiter">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:title" content="[NOTES] Self-Normalizing Neural Networks (SELU)">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://dtsbourg.github.io/thoughts/posts/self-normalizing-neural-nets">
  <meta property="og:description" content="by G. Klambauer, T. Unterthiner, A. Mayr, and S. Hochreiter">
  <meta property="og:site_name" content="dtsbourg / Thoughts">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:url" content="https://dtsbourg.github.io/thoughts/posts/self-normalizing-neural-nets">
  <meta name="twitter:title" content="[NOTES] Self-Normalizing Neural Networks (SELU)">
  <meta name="twitter:description" content="by G. Klambauer, T. Unterthiner, A. Mayr, and S. Hochreiter">

  
    <meta property="og:image" content="https://dtsbourg.github.io/thoughts/assets/ico/mstile-310x310-e9fa2f241f5031a41a72732fe98163878d1e0bf693d8c4428ff88f1f0e39bb08.png">
    <meta name="twitter:image" content="https://dtsbourg.github.io/thoughts/assets/ico/mstile-310x310-e9fa2f241f5031a41a72732fe98163878d1e0bf693d8c4428ff88f1f0e39bb08.png">
  

  <link href="https://dtsbourg.github.io/thoughts/feed.xml" type="application/rss+xml" rel="alternate" title="dtsbourg / Thoughts Last 10 blog posts" />

  

  
    <link rel="icon" type="image/x-icon" href="/thoughts/assets/ico/favicon-41b12d58bbe584707b26dfe14aa183924e6f4ae99b3fb386b15793a86c47f2b2.ico">
    <link rel="apple-touch-icon" href="/thoughts/assets/ico/apple-touch-icon-48c3ef4f42ae5e034dd98190216d8cbdd52db47b0655e1dea866e2f28f93a472.png">
    <link rel="stylesheet" type="text/css" href="/thoughts/assets/light-b34f12b58415aa3a5f6cf5f4caec8a9f2971a5aba876b1956e66ddb8dc92581f.css">
  
</head>

<body>
  <main>
    <div class="grid grid-centered">
      <div class="grid-cell">
        <nav class="header-nav scrollappear">
  <a href="/thoughts/" class="header-logo" title="dtsbourg / Thoughts">dtsbourg / Thoughts</a>
  <ul class="header-links">
    
    
      <li>
        <a href="https://twitter.com/dtsbourg" rel="noreferrer noopener" target="_blank" title="Twitter">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-twitter">
  <use href="/thoughts/assets/twitter-8842c33965263ad1b03a978406826677a668f94125d5837e70ab83f24b3213a7.svg#icon-twitter" xlink:href="/thoughts/assets/twitter-8842c33965263ad1b03a978406826677a668f94125d5837e70ab83f24b3213a7.svg#icon-twitter"></use>
</svg>

        </a>
      </li>
    
    
    
    
      <li>
        <a href="https://github.com/dtsbourg" rel="noreferrer noopener" target="_blank" title="GitHub">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-github">
  <use href="/thoughts/assets/github-094f81040819f34343ee6ffff0980f17e2807b08b595eaaf66ae3554934fd78d.svg#icon-github" xlink:href="/thoughts/assets/github-094f81040819f34343ee6ffff0980f17e2807b08b595eaaf66ae3554934fd78d.svg#icon-github"></use>
</svg>

        </a>
      </li>
    
    
    
    
    
    
    
      <li>
        <a href="https://www.linkedin.com/in/dylan-bourgeois-319ab294" rel="noreferrer noopener" target="_blank" title="LinkedIn">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-linkedin">
  <use href="/thoughts/assets/linkedin-cdc5c107044324a3dfbea2e9ead15873f8dee304c37d73a046988956b706256e.svg#icon-linkedin" xlink:href="/thoughts/assets/linkedin-cdc5c107044324a3dfbea2e9ead15873f8dee304c37d73a046988956b706256e.svg#icon-linkedin"></use>
</svg>

        </a>
      </li>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
      <li>
        <a href="/thoughts/feed.xml" rel="noreferrer noopener" target="_blank" title="RSS">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-rss">
  <use href="/thoughts/assets/rss-541ec5cea9cefd10d2fcfec01888f3f231a8829940249835fa7b7b3a12ae0d0d.svg#icon-rss" xlink:href="/thoughts/assets/rss-541ec5cea9cefd10d2fcfec01888f3f231a8829940249835fa7b7b3a12ae0d0d.svg#icon-rss"></use>
</svg>

        </a>
      </li>
    
  </ul>
</nav>

        <article class="article scrollappear">
          <header class="article-header">
            <h1>[NOTES] Self-Normalizing Neural Networks (SELU)</h1>
            <p>by G. Klambauer, T. Unterthiner, A. Mayr, and S. Hochreiter</p>
            <div class="article-list-footer">
              <span class="article-list-date">
                March 23, 2018
              </span>
              <span class="article-list-divider">-</span>
              <span class="article-list-minutes">
                
                
                  3 minute read
                
              </span>
              <span class="article-list-divider">-</span>
              <div class="article-list-tags">
                
                  <a href="/thoughts/tag/ml">ml</a>
                
                  <a href="/thoughts/tag/deeplearning">deeplearning</a>
                
                  <a href="/thoughts/tag/notes">notes</a>
                
              </div>
            </div>
          </header>

          <div class="article-content">
            <p><a href="https://arxiv.org/abs/1706.02515">arXiv</a></p>

<h2 id="what">What?</h2>

<p>Proposes a new activation function allowing the robust training of very
deep vanilla neural networks.</p>

<h2 id="why">Why?</h2>

<p>Most of the successes of Deep Learning have come either from Recurrent (RNN)
or Convolutional (CNN) forms: they are stable through weight-sharing.
Vanilla Neural Networks suffer from training
instabilities mainly due to SGD being unstable after a few layers (vanishing or
exploding gradients).</p>

<p>Some methods have been proposed, notably <strong>batch normalization</strong> <sup id="fnref:3"><a href="#fn:3" class="footnote">1</a></sup> which
brings activations to zero-mean and unit variance, but they are perturbed by
stochastic regularisation methods (e.g. dropout <sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup>).</p>

<p>Normalizing activations avoids a bias in the inputs of the following layer.</p>

<h2 id="how">How?</h2>

<p>An activation function is designed along the following requirements:</p>

<ol>
  <li>Negative and Positive values for controlling the mean</li>
  <li>Saturation regions (zero-gradient) to control the exploding gradient problem</li>
  <li>Slope larger than 1 to increase the variance if necessary</li>
  <li>Continuous curve</li>
</ol>

<p>Derive a mapping between layers that satisfies these requirements. Interestingly
the properties are verified through a computer-aided proof. The starting point
is mix between Exponential Linear Units (ELUs) and Leaky ReLUs.</p>

<script type="math/tex; mode=display">% <![CDATA[
selu(x) = \lambda  \begin{cases} x & \text{ if } x \gt 0 \\ \alpha e^{x} - \alpha & \text{ if } x \le 0 \end{cases} %]]></script>

<p>Parameters are obtained by finding a fixed point of the mapping function that
satisfies the normalization requirements. They propose:</p>

<p><script type="math/tex">\alpha = 1.6732632423543772848170429916717</script>
<script type="math/tex">\lambda = 1.0507009873554804934193349852946</script></p>

<p>They also derive a parametrised dropout which does not suffer from the same issues
as regular dropout as it is designed to preserve zero-mean and unit-variance in
the layer’s activations.</p>

<p><a href="/thoughts/assets/selu/selu-ed5c2fb433f4cb203597437937822f0c0d482bbf9faf134c5bcf1aaed857d5d4.png">
  <img src="/thoughts/assets/selu/selu-ed5c2fb433f4cb203597437937822f0c0d482bbf9faf134c5bcf1aaed857d5d4.png" alt="Selu" class="zooming" data-rjs="/thoughts/assets/selu/selu-ed5c2fb433f4cb203597437937822f0c0d482bbf9faf134c5bcf1aaed857d5d4.png" data-zooming-width="600" data-zooming-height="400" />
</a></p>

<p><em>Figure 1: SELU activation function</em></p>

<h2 id="evaluation">Evaluation</h2>

<ul>
  <li>121 Tasks from <a href="https://archive.ics.uci.edu/ml/datasets.html">UCI dataset</a></li>
  <li>Drug discovery task</li>
  <li>Astronomy task</li>
</ul>

<p><a href="/thoughts/assets/selu/snn_accuracies-741053df41cd39f29a9dd736f47f65f7601cb39119c52b50831f3545ace4639e.png">
  <img src="/thoughts/assets/selu/snn_accuracies-741053df41cd39f29a9dd736f47f65f7601cb39119c52b50831f3545ace4639e.png" alt="accuracy" class="zooming" data-rjs="/thoughts/assets/selu/snn_accuracies-741053df41cd39f29a9dd736f47f65f7601cb39119c52b50831f3545ace4639e.png" data-zooming-width="1582" data-zooming-height="852" />
</a></p>

<p><em>Figure 2: Image from Klambauer et al, https://arxiv.org/abs/1706.02515 [license http://arxiv.org/licenses/nonexclusive-distrib/1.0/]</em></p>

<p>Compare against many baselines: Batch Norm, Layer Norm, Weight Norm, Highway, ResNet.</p>

<h2 id="comments">Comments</h2>

<ul>
  <li>Interesting use of a computer generated proof to give bounds on the variance
when weights don’t satisfy the zero-mean, unit-variance property</li>
  <li>Very smooth accuracy even for very deep networks (see Fig. 2)</li>
  <li>Sepp Hochreiter <sup id="fnref:1"><a href="#fn:1" class="footnote">3</a></sup></li>
  <li>Makes batchnorm obsolete, which means big training speedup</li>
</ul>

<h2 id="questions">Questions</h2>

<ul>
  <li>Evaluated with SGD. How does it behave with e.g. Adam?</li>
  <li>Evaluated with small learning rates, can we be more agressive in learning?</li>
  <li>Comparison between Spectral Normalization <sup id="fnref:4"><a href="#fn:4" class="footnote">4</a></sup> and SNN for mode collapse in GANs.</li>
</ul>

<h2 id="resources">Resources</h2>
<h4 id="code">Code</h4>

<ul>
  <li><a href="https://github.com/bioinf-jku/SNNs">Tensorflow Implementation</a></li>
  <li><a href="https://github.com/dannysdeng/selu">PyTorch Implementation</a></li>
  <li><a href="https://gist.github.com/Drakensberge/2d8a4e8f9ff48e095e12a892b08598ec#file-distribution-ipynb">Notebook</a></li>
</ul>

<h4 id="discussion">Discussion</h4>

<ul>
  <li><a href="https://www.reddit.com/r/MachineLearning/comments/6g5tg1/r_selfnormalizing_neural_networks_improved_elu/">/r/MachineLearning</a></li>
  <li><a href="https://news.ycombinator.com/item?id=14527686">hackernews</a></li>
  <li><a href="http://www.shortscience.org/paper?bibtexKey=journals/corr/1706.02515">Shortscience</a></li>
</ul>

<h2 id="references">References</h2>

<div class="footnotes">
  <ol>
    <li id="fn:3">
      <p><a href="https://arxiv.org/abs/1502.03167"><em>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</em>, Sergey Ioffe, Christian Szegedy</a> <a href="#fnref:3" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p><a href="http://jmlr.org/papers/v15/srivastava14a.html"><em>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</em>, Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov; 15(Jun):1929−1958, 2014.</a> <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:1">
      <p><a href="https://dl.acm.org/citation.cfm?id=1246450"><em>Long Short-Term Memory</em>. Sepp Hochreiter and Jürgen Schmidhuber.  Neural Comput. 9, 8 (November 1997), 1735-1780</a> <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p><a href="https://openreview.net/forum?id=B1QRgziT-"><em>Spectral Normalization for Generative Adversarial Networks</em>, Takeru Miyato, Toshiki Kataoka, Masanori Koyama, Yuichi Yoshida</a> <a href="#fnref:4" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

          </div>
          <div class="article-share">
            
            
            <a href="https://twitter.com/home?status=[NOTES]+Self-Normalizing+Neural+Networks+(SELU)%20-%20https://dtsbourg.github.io/thoughts/posts/self-normalizing-neural-nets%20by%20@dtsbourg" title="Share on Twitter" rel="noreferrer noopener" target="_blank">
              <svg viewBox="0 0 512 512"><path d="M492 109.5c-17.4 7.7-36 12.9-55.6 15.3 20-12 35.4-31 42.6-53.6 -18.7 11.1-39.4 19.2-61.5 23.5C399.8 75.8 374.6 64 346.8 64c-53.5 0-96.8 43.4-96.8 96.9 0 7.6 0.8 15 2.5 22.1 -80.5-4-151.9-42.6-199.6-101.3 -8.3 14.3-13.1 31-13.1 48.7 0 33.6 17.2 63.3 43.2 80.7C67 210.7 52 206.3 39 199c0 0.4 0 0.8 0 1.2 0 47 33.4 86.1 77.7 95 -8.1 2.2-16.7 3.4-25.5 3.4 -6.2 0-12.3-0.6-18.2-1.8 12.3 38.5 48.1 66.5 90.5 67.3 -33.1 26-74.9 41.5-120.3 41.5 -7.8 0-15.5-0.5-23.1-1.4C62.8 432 113.7 448 168.3 448 346.6 448 444 300.3 444 172.2c0-4.2-0.1-8.4-0.3-12.5C462.6 146 479 129 492 109.5z"/></svg>
            </a>
            <a href="https://www.facebook.com/sharer/sharer.php?u=https://dtsbourg.github.io/thoughts/posts/self-normalizing-neural-nets" title="Share on Facebook" rel="noreferrer noopener" target="_blank">
              <svg viewBox="0 0 512 512"><path d="M288 192v-38.1c0-17.2 3.8-25.9 30.5-25.9H352V64h-55.9c-68.5 0-91.1 31.4-91.1 85.3V192h-45v64h45v192h83V256h56.4l7.6-64H288z"/></svg>
            </a>
            <a href="https://plus.google.com/share?url=https://dtsbourg.github.io/thoughts/posts/self-normalizing-neural-nets" title="Share on Google+" rel="noreferrer noopener" target="_blank">
              <svg viewBox="0 0 128 128"><path d="M40.7 55.9v16.1c0 0 15.6 0 22 0C59.2 82.5 53.8 88.2 40.7 88.2c-13.3 0-23.7-10.8-23.7-24.2s10.4-24.2 23.7-24.2c7.1 0 11.6 2.5 15.8 5.9 3.3-3.3 3.1-3.8 11.6-11.9 -7.2-6.6-16.8-10.6-27.4-10.6C18.2 23.3 0 41.5 0 64c0 22.5 18.2 40.7 40.7 40.7 33.6 0 41.8-29.3 39-48.8H40.7zM113.9 56.7V42.6h-10.1v14.1H89.4v10.1h14.5v14.5h10.1V66.8H128V56.7H113.9z"/></svg>
            </a>
          </div>

          
        </article>
        <footer class="footer appear">
  <p>
    I'm
    <a href="https://dtsbourg.github.io" title="About me">Dylan Bourgeois</a>. I study robots and their brains.
  </p>
</footer>

      </div>
    </div>
  </main>
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-65856095-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-65856095-1');
  </script>


<script src="/thoughts/assets/vendor-0fb4b91f7ad6c193a69224eba7a01b691a2d7528ee672607575ccc0df3aea545.js" type="text/javascript"></script>


  <script src="/thoughts/assets/webfonts-96493456d319d1bf419afdf8701552d4d486fee6afd304897d4fd81eb4e0cc0b.js" type="text/javascript"></script>



  <script src="/thoughts/assets/scrollappear-e2da8ea567e418637e31266cc5302126eaa79f62a2273739086358b589a89ee6.js" type="text/javascript"></script>


<script src="/thoughts/assets/application-cfde13ac81ddaf4351b2e739603e2baf688d0fcc9aba613fe62bbb1c7b037fb9.js" type="text/javascript"></script>

</body>
</html>
